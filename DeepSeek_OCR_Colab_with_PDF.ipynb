{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepSeek-OCR Testing Notebook (with PDF Support)\n",
    "\n",
    "**Setup Guide**: This notebook tests DeepSeek-OCR on Google Colab Pro\n",
    "\n",
    "## Requirements\n",
    "- Google Colab Pro (for guaranteed GPU access)\n",
    "- ~15-20 minutes first run (model download)\n",
    "- ~2 minutes subsequent runs (cached)\n",
    "\n",
    "## What This Does\n",
    "1. ‚úÖ Checks GPU availability\n",
    "2. ‚úÖ Installs dependencies (CUDA-enabled PyTorch, flash-attention)\n",
    "3. ‚úÖ Downloads DeepSeek-OCR model (~8GB)\n",
    "4. ‚úÖ Tests with sample images\n",
    "5. ‚úÖ Processes your own images\n",
    "6. ‚úÖ **NEW: Processes PDF documents** üìÑ\n",
    "\n",
    "## Instructions\n",
    "1. **Runtime ‚Üí Change runtime type ‚Üí T4 GPU** (or better)\n",
    "2. **Runtime ‚Üí Run all**\n",
    "3. Wait for completion (progress bars will show)\n",
    "4. Upload your images/PDFs in the processing cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(f\"\\nüî• PyTorch version: {torch.__version__}\")\n",
    "print(f\"üéÆ CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"üöÄ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No GPU found! Go to Runtime ‚Üí Change runtime type ‚Üí Select GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Clone DeepSeek-OCR Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository (includes sample images)\n",
    "!git clone https://github.com/deepseek-ai/DeepSeek-OCR.git\n",
    "%cd DeepSeek-OCR\n",
    "!ls -la assets/  # Show sample images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: Install Dependencies\n",
    "\n",
    "This will take ~5-10 minutes. Installing:\n",
    "- PyTorch 2.6.0 with CUDA 11.8\n",
    "- Flash Attention 2.7.3\n",
    "- Transformers, PyMuPDF, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install PyTorch with CUDA 11.8\n",
    "!pip install -q torch==2.6.0 torchvision==0.21.0 torchaudio==2.6.0 --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install other requirements\n",
    "!pip install -q transformers==4.46.3 tokenizers==0.20.3 PyMuPDF img2pdf einops easydict addict Pillow numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Flash Attention (takes ~3-5 minutes to build)\n",
    "print(\"‚öôÔ∏è  Building Flash Attention... This takes 3-5 minutes\")\n",
    "!pip install -q flash-attn==2.7.3 --no-build-isolation\n",
    "print(\"‚úÖ Flash Attention installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: Load DeepSeek-OCR Model\n",
    "\n",
    "**First run**: Downloads ~8GB model (5-10 minutes)\n",
    "\n",
    "**Subsequent runs**: Uses cached model (30 seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "import os\n",
    "\n",
    "print(\"üì• Loading DeepSeek-OCR model...\")\n",
    "print(\"‚è≥ First run: ~5-10 min download | Cached runs: ~30 sec\")\n",
    "\n",
    "model_name = 'deepseek-ai/DeepSeek-OCR'\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name, \n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# Load model\n",
    "model = AutoModel.from_pretrained(\n",
    "    model_name,\n",
    "    _attn_implementation='flash_attention_2',\n",
    "    trust_remote_code=True,\n",
    "    use_safetensors=True\n",
    ")\n",
    "\n",
    "# Move to GPU and set to eval mode\n",
    "model = model.eval().cuda().to(torch.bfloat16)\n",
    "\n",
    "print(\"‚úÖ Model loaded successfully!\")\n",
    "print(f\"üéØ Model is on: {next(model.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 5: Test with Sample Images\n",
    "\n",
    "Run OCR on the included sample images to verify everything works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with sample image\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Display sample image\n",
    "image_path = 'assets/show1.jpg'\n",
    "img = Image.open(image_path)\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.title('Sample Image')\n",
    "plt.show()\n",
    "\n",
    "print(f\"üìê Image size: {img.size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1: Convert Document to Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîç Running OCR with Markdown conversion...\\n\")\n",
    "\n",
    "prompt = \"<image>\\n<|grounding|>Convert the document to markdown.\"\n",
    "output_path = './output'\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "result = model.infer(\n",
    "    tokenizer,\n",
    "    prompt=prompt,\n",
    "    image_file=image_path,\n",
    "    output_path=output_path,\n",
    "    base_size=1024,      # Base resolution\n",
    "    image_size=640,      # Crop size\n",
    "    crop_mode=True,      # Dynamic resolution (Gundam mode)\n",
    "    save_results=True,\n",
    "    test_compress=True\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üìÑ RESULT:\")\n",
    "print(\"=\"*50)\n",
    "print(result[:500])  # Show first 500 chars\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 6: Process Your Own Images üñºÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload images\n",
    "from google.colab import files\n",
    "import io\n",
    "\n",
    "print(\"üì§ Click 'Choose Files' to upload your images...\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "print(f\"\\n‚úÖ Uploaded {len(uploaded)} file(s)\")\n",
    "for filename in uploaded.keys():\n",
    "    print(f\"  - {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process uploaded images\n",
    "from PIL import Image\n",
    "\n",
    "# Configuration\n",
    "PROMPT = \"<image>\\n<|grounding|>Convert the document to markdown.\"  # Change this!\n",
    "OUTPUT_DIR = './user_outputs'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "for filename in uploaded.keys():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"üìÑ Processing: {filename}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Display image\n",
    "    img = Image.open(io.BytesIO(uploaded[filename]))\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(filename)\n",
    "    plt.show()\n",
    "    \n",
    "    # Save temporarily\n",
    "    temp_path = f'/tmp/{filename}'\n",
    "    with open(temp_path, 'wb') as f:\n",
    "        f.write(uploaded[filename])\n",
    "    \n",
    "    # Run inference\n",
    "    result = model.infer(\n",
    "        tokenizer,\n",
    "        prompt=PROMPT,\n",
    "        image_file=temp_path,\n",
    "        output_path=OUTPUT_DIR,\n",
    "        base_size=1024,\n",
    "        image_size=640,\n",
    "        crop_mode=True,\n",
    "        save_results=True,\n",
    "        test_compress=True\n",
    "    )\n",
    "    \n",
    "    # Save result\n",
    "    result_file = os.path.join(OUTPUT_DIR, f\"{filename}_result.md\")\n",
    "    with open(result_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(result)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Saved to: {result_file}\")\n",
    "    print(f\"\\nüìÑ Result preview:\\n{'-'*60}\")\n",
    "    print(result[:1000])  # Show first 1000 chars\n",
    "\n",
    "print(f\"\\n\\nüéâ All images processed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 7: Process PDF Documents üìÑ\n",
    "\n",
    "**NEW!** Upload PDFs and process all pages automatically.\n",
    "\n",
    "This will:\n",
    "1. Convert each PDF page to an image\n",
    "2. Process all pages with OCR\n",
    "3. Compile results into a single markdown file\n",
    "4. Add page separators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload PDFs\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "print(\"üì§ Click 'Choose Files' to upload your PDF(s)...\")\n",
    "uploaded_pdfs = files.upload()\n",
    "\n",
    "print(f\"\\n‚úÖ Uploaded {len(uploaded_pdfs)} PDF(s)\")\n",
    "for filename in uploaded_pdfs.keys():\n",
    "    print(f\"  - {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to convert PDF to images\n",
    "def pdf_to_images(pdf_bytes, dpi=144):\n",
    "    \"\"\"\n",
    "    Convert PDF to list of PIL Images\n",
    "    \n",
    "    Args:\n",
    "        pdf_bytes: PDF file bytes\n",
    "        dpi: Resolution (144 is good balance, 72=fast/low quality, 300=slow/high quality)\n",
    "    \n",
    "    Returns:\n",
    "        List of PIL Images\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    pdf_document = fitz.open(stream=pdf_bytes, filetype=\"pdf\")\n",
    "    \n",
    "    zoom = dpi / 72.0\n",
    "    matrix = fitz.Matrix(zoom, zoom)\n",
    "    \n",
    "    for page_num in range(pdf_document.page_count):\n",
    "        page = pdf_document[page_num]\n",
    "        pixmap = page.get_pixmap(matrix=matrix, alpha=False)\n",
    "        \n",
    "        # Convert to PIL Image\n",
    "        img_data = pixmap.tobytes(\"png\")\n",
    "        img = Image.open(io.BytesIO(img_data))\n",
    "        images.append(img)\n",
    "    \n",
    "    pdf_document.close()\n",
    "    return images\n",
    "\n",
    "print(\"‚úÖ PDF conversion function ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process PDFs\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Configuration\n",
    "PDF_PROMPT = \"<image>\\n<|grounding|>Convert the document to markdown.\"\n",
    "PDF_OUTPUT_DIR = './pdf_outputs'\n",
    "os.makedirs(PDF_OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Process each PDF\n",
    "for pdf_filename in uploaded_pdfs.keys():\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"üìÑ Processing PDF: {pdf_filename}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    # Convert PDF to images\n",
    "    print(\"üîÑ Converting PDF to images...\")\n",
    "    pdf_bytes = io.BytesIO(uploaded_pdfs[pdf_filename])\n",
    "    page_images = pdf_to_images(pdf_bytes, dpi=144)  # Lower DPI=faster, higher=better quality\n",
    "    print(f\"‚úÖ Converted {len(page_images)} pages\\n\")\n",
    "    \n",
    "    # Process each page\n",
    "    all_results = []\n",
    "    \n",
    "    for page_num, page_img in enumerate(tqdm(page_images, desc=f\"Processing pages\")):\n",
    "        # Show preview of first page and every 5th page\n",
    "        if page_num == 0 or (page_num + 1) % 5 == 0:\n",
    "            plt.figure(figsize=(8, 10))\n",
    "            plt.imshow(page_img)\n",
    "            plt.axis('off')\n",
    "            plt.title(f'Page {page_num + 1}')\n",
    "            plt.show()\n",
    "        \n",
    "        # Save page temporarily\n",
    "        temp_page_path = f'/tmp/page_{page_num}.png'\n",
    "        page_img.save(temp_page_path)\n",
    "        \n",
    "        # Run OCR\n",
    "        try:\n",
    "            result = model.infer(\n",
    "                tokenizer,\n",
    "                prompt=PDF_PROMPT,\n",
    "                image_file=temp_page_path,\n",
    "                output_path=PDF_OUTPUT_DIR,\n",
    "                base_size=1024,\n",
    "                image_size=640,\n",
    "                crop_mode=True,\n",
    "                save_results=False,\n",
    "                test_compress=True\n",
    "            )\n",
    "            \n",
    "            # Add page header and separator\n",
    "            page_result = f\"\\n## Page {page_num + 1}\\n\\n{result}\\n\\n---\\n\"\n",
    "            all_results.append(page_result)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  Error on page {page_num + 1}: {e}\")\n",
    "            all_results.append(f\"\\n## Page {page_num + 1}\\n\\n*Error processing this page*\\n\\n---\\n\")\n",
    "    \n",
    "    # Compile all pages into single markdown file\n",
    "    pdf_base_name = pdf_filename.replace('.pdf', '')\n",
    "    output_file = os.path.join(PDF_OUTPUT_DIR, f\"{pdf_base_name}_complete.md\")\n",
    "    \n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        # Write header\n",
    "        f.write(f\"# {pdf_filename}\\n\\n\")\n",
    "        f.write(f\"**Total Pages**: {len(page_images)}\\n\\n\")\n",
    "        f.write(f\"**Successfully Processed**: {len([r for r in all_results if 'Error' not in r])} pages\\n\\n\")\n",
    "        f.write(f\"**Generated**: {os.popen('date').read().strip()}\\n\\n\")\n",
    "        f.write(\"---\\n\\n\")\n",
    "        # Write all pages\n",
    "        f.writelines(all_results)\n",
    "    \n",
    "    print(f\"\\n‚úÖ PDF processed!\")\n",
    "    print(f\"üìÅ Saved to: {output_file}\")\n",
    "    print(f\"üìä Total pages: {len(page_images)}\")\n",
    "    print(f\"üìù File size: {os.path.getsize(output_file) / 1024:.1f} KB\")\n",
    "\n",
    "print(f\"\\n\\nüéâ All PDFs processed! Results in: {PDF_OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preview PDF Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show preview of each PDF result\n",
    "import glob\n",
    "\n",
    "pdf_results = glob.glob(os.path.join(PDF_OUTPUT_DIR, '*_complete.md'))\n",
    "\n",
    "for result_file in pdf_results:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"üìÑ {os.path.basename(result_file)}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    with open(result_file, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "        # Show first 2000 characters\n",
    "        print(content[:2000])\n",
    "        if len(content) > 2000:\n",
    "            print(f\"\\n... (showing first 2000 chars out of {len(content)} total)\")\n",
    "            print(f\"\\nüí° Download the full file to see all content!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 8: Download All Results üì¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip and download all results (images + PDFs)\n",
    "import shutil\n",
    "\n",
    "# Collect all output directories\n",
    "output_dirs = []\n",
    "if os.path.exists(OUTPUT_DIR):\n",
    "    output_dirs.append(OUTPUT_DIR)\n",
    "if os.path.exists(PDF_OUTPUT_DIR):\n",
    "    output_dirs.append(PDF_OUTPUT_DIR)\n",
    "\n",
    "if output_dirs:\n",
    "    # Create combined directory\n",
    "    combined_dir = './all_results'\n",
    "    os.makedirs(combined_dir, exist_ok=True)\n",
    "    \n",
    "    # Copy all results\n",
    "    for output_dir in output_dirs:\n",
    "        dir_name = os.path.basename(output_dir)\n",
    "        target_dir = os.path.join(combined_dir, dir_name)\n",
    "        if os.path.exists(target_dir):\n",
    "            shutil.rmtree(target_dir)\n",
    "        shutil.copytree(output_dir, target_dir)\n",
    "    \n",
    "    # Create zip file\n",
    "    print(\"üì¶ Creating zip file...\")\n",
    "    shutil.make_archive('deepseek_ocr_results', 'zip', combined_dir)\n",
    "    \n",
    "    # Download\n",
    "    print(\"‚¨áÔ∏è  Downloading results...\")\n",
    "    files.download('deepseek_ocr_results.zip')\n",
    "    print(\"‚úÖ Downloaded!\")\n",
    "    \n",
    "    # Show summary\n",
    "    print(f\"\\nüìä Summary:\")\n",
    "    if os.path.exists(OUTPUT_DIR):\n",
    "        img_files = len([f for f in os.listdir(OUTPUT_DIR) if f.endswith('.md')])\n",
    "        print(f\"  üì∏ Image results: {img_files}\")\n",
    "    if os.path.exists(PDF_OUTPUT_DIR):\n",
    "        pdf_files = len([f for f in os.listdir(PDF_OUTPUT_DIR) if f.endswith('.md')])\n",
    "        print(f\"  üìÑ PDF results: {pdf_files}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No results to download yet. Process some images or PDFs first!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üéØ Tips & Configuration\n",
    "\n",
    "### Resolution Modes\n",
    "\n",
    "Adjust quality vs speed by changing these parameters:\n",
    "\n",
    "```python\n",
    "# Tiny: Fastest, lowest quality (64 vision tokens)\n",
    "base_size=512, image_size=512, crop_mode=False\n",
    "\n",
    "# Small: Fast, good quality (100 vision tokens)\n",
    "base_size=640, image_size=640, crop_mode=False\n",
    "\n",
    "# Base: Balanced (256 vision tokens)\n",
    "base_size=1024, image_size=1024, crop_mode=False\n",
    "\n",
    "# Large: Slow, best quality (400 vision tokens)\n",
    "base_size=1280, image_size=1280, crop_mode=False\n",
    "\n",
    "# Gundam: Dynamic, best for documents (256 + n√ó100 tokens)\n",
    "base_size=1024, image_size=640, crop_mode=True  # ‚Üê DEFAULT\n",
    "```\n",
    "\n",
    "### PDF Quality Settings\n",
    "\n",
    "In the `pdf_to_images()` function, adjust DPI:\n",
    "\n",
    "```python\n",
    "page_images = pdf_to_images(pdf_bytes, dpi=144)  # ‚Üê Change this\n",
    "\n",
    "# dpi=72:  Fast, lower quality\n",
    "# dpi=144: Balanced (default)\n",
    "# dpi=300: Slow, best quality\n",
    "```\n",
    "\n",
    "### Common Prompts\n",
    "\n",
    "```python\n",
    "# Documents to markdown (best for PDFs)\n",
    "\"<image>\\n<|grounding|>Convert the document to markdown.\"\n",
    "\n",
    "# General OCR\n",
    "\"<image>\\n<|grounding|>OCR this image.\"\n",
    "\n",
    "# Text only (no layout)\n",
    "\"<image>\\nFree OCR.\"\n",
    "\n",
    "# Parse figures/charts\n",
    "\"<image>\\nParse the figure.\"\n",
    "\n",
    "# General description\n",
    "\"<image>\\nDescribe this image in detail.\"\n",
    "```\n",
    "\n",
    "### Performance\n",
    "\n",
    "| Task | Time per Page | GPU Memory |\n",
    "|------|---------------|------------|\n",
    "| Image (Tiny) | ~5 sec | ~8 GB |\n",
    "| Image (Gundam) | ~10 sec | ~12 GB |\n",
    "| Image (Large) | ~15 sec | ~14 GB |\n",
    "| PDF (10 pages) | ~2 min | ~12 GB |\n",
    "| PDF (50 pages) | ~10 min | ~12 GB |\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Resources\n",
    "\n",
    "- [DeepSeek-OCR Paper](https://arxiv.org/abs/2510.18234)\n",
    "- [Model on HuggingFace](https://huggingface.co/deepseek-ai/DeepSeek-OCR)\n",
    "- [GitHub Repository](https://github.com/deepseek-ai/DeepSeek-OCR)\n",
    "\n",
    "---\n",
    "\n",
    "**Created by**: Carlos Lorenzo Santos\n",
    "\n",
    "**Date**: October 2025\n",
    "\n",
    "**Model**: DeepSeek-OCR"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
